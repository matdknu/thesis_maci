{
  "hash": "38b5d77fb337659de8548dba27da5cd4",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Diseño metodológico\"\nlang: es\n---\n\n\n\n\n\n\n\n\nEsta investigación adopta un diseño **longitudinal observacional** basado en el análisis de datos digitales generados por usuarios (*user-generated content*). El carácter longitudinal permite capturar la evolución temporal del debate político a lo largo del ciclo electoral, identificando patrones de variación, puntos de inflexión y dinámicas de cambio. El carácter observacional implica que los datos son recolectados sin intervención experimental, preservando las características naturales de la interacción en las plataformas estudiadas.\n\nMetodológicamente, la investigación se inscribe en el campo emergente de la **ciencia social computacional** (*computational social science*), que integra técnicas de procesamiento de datos a gran escala con los marcos teóricos y las preguntas sustantivas de las ciencias sociales (Lazer et al., 2009; Salganik, 2019). Esta aproximación permite analizar volúmenes de datos textuales que excederían las capacidades del análisis cualitativo tradicional, mientras mantiene un compromiso con la interpretación teóricamente informada de los patrones identificados.\n\nEl diseño combina componentes **descriptivos**, orientados a caracterizar la conversación política en Reddit durante el período estudiado, con componentes **explicativos**, orientados a identificar los factores y mecanismos que dan cuenta de los patrones observados. Esta combinación responde a la naturaleza de las preguntas de investigación, que demandan tanto una cartografía del terreno empírico como una comprensión de las dinámicas que lo estructuran.\n\n## Recolección de datos: web scraping mediante API\n\n###  Procedimiento técnico\n\nLos datos fueron extraídos mediante **web scraping** utilizando la API pública de Reddit a través de la librería PRAW (*Python Reddit API Wrapper*). Esta aproximación permite acceder de forma estructurada y sistemática al contenido público de la plataforma, respetando los límites de uso establecidos por Reddit y garantizando la trazabilidad y reproducibilidad del proceso de recolección.\n\nEl scraping se realizó sobre los dos subreddits principales de la comunidad chilena:\n\n-   **r/chile**: Comunidad generalista sobre temas chilenos, con mayor volumen de usuarios y diversidad temática.\n\n-   **r/RepublicadeChile**: Comunidad alternativa surgida como escisión de r/chile, caracterizada por una composición ideológica distintiva y políticas de moderación más permisivas.\n\nEstos espacios fueron seleccionados por constituir los principales foros de discusión política chilena en la plataforma, caracterizados por participación activa, diversidad de perspectivas ideológicas y debates sostenidos sobre temas de contingencia nacional.\n\n### Período temporal\n\nLa recolección de datos abarcó **cinco meses**, desde el **1 de agosto hasta el 31 de diciembre de 2024**. Este período temporal captura diferentes fases del ciclo electoral presidencial chileno de 2025:\n\n-   **Agosto-octubre 2024**: Fase de emergencia de candidaturas, posicionamiento inicial y primeras definiciones programáticas.\n\n-   **Noviembre-diciembre 2024**: Período de escalamiento de campaña, consolidación electoral y estructuración del debate público.\n\nLa ventana temporal de cinco meses permite observar la evolución dinámica del debate político, identificar patrones temporales de activación discursiva y capturar tanto tendencias sostenidas como picos de discusión asociados a eventos políticos específicos del período (debates televisados, declaraciones públicas, controversias mediáticas).\n\n### Estrategia de scraping incremental\n\nEl proceso de recolección fue **incremental y acumulativo**, ejecutándose en múltiples iteraciones programadas que:\n\n1.  **Extracción**: Recuperaban los posts más recientes disponibles en cada subreddit (límite de 250-1000 posts por ejecución según configuración).\n\n2.  **Expansión**: Descargaban el árbol completo de comentarios de cada post relevante mediante `replace_more(limit=None)` para capturar todos los niveles de anidación conversacional.\n\n3.  **Acumulación**: Integraban nuevos datos con extracciones previas en archivos CSV, Parquet y Excel.\n\n4.  **Deduplicación**: Eliminaban registros duplicados mediante identificadores únicos generados con hashes SHA-256 basados en: post_id + timestamp + autor + contenido textual.\n\nEste diseño iterativo permitió maximizar la cobertura temporal sin exceder los límites de la API, capturar discusiones en desarrollo a lo largo de los cinco meses y construir un corpus longitudinal que refleja la evolución dinámica del debate político.\n\n### Filtrado temático\n\nPara cada publicación dentro del rango temporal, se extrajeron dos niveles de contenido textual:\n\n**Nivel de publicación (posts)**:\n\n-   Título (*title*): Encabezado del post que condensa el tema o posición principal.\n\n-   Cuerpo (*selftext*): Texto completo de la publicación cuando el formato lo incluye.\n\n-   Metadatos: autor, fecha de creación, puntuación, número de comentarios, flair (etiqueta temática).\n\n**Nivel de comentarios**:\n\n-   Cuerpo del comentario (*comment_body*): Texto completo de cada comentario en el árbol de discusión.\n\n-   Metadatos: autor, fecha de creación, puntuación, relación con post padre e identificador del comentario al que responde.\n\nAmbos niveles de texto fueron procesados mediante **expresiones regulares** que identifican menciones de figuras políticas específicas, manejando variaciones ortográficas comunes (presencia/ausencia de acentos, nombres completos vs. apellidos, apodos políticos, errores tipográficos frecuentes). Este filtrado temático permite construir un corpus focalizado en la discusión sobre las candidaturas presidenciales de interés.\n\n### Figuras políticas de interés\n\nEl filtrado temático se centró en cuatro candidaturas representativas de las distintas corrientes ideológicas:\n\n| Candidatura       | Corriente ideológica         | Patrones de búsqueda               |\n|-------------------|------------------------------|------------------------------------|\n| Evelyn Matthei    | Derecha tradicional          | \"matthei\", \"matei\", \"evelyn\"       |\n| José Antonio Kast | Derecha radical-conservadora | \"kast\", \"jose antonio kast\", \"jak\" |\n| Johannes Kaiser   | Derecha libertaria           | \"kaiser\", \"johannes\", \"jkaiser\"    |\n| Jeannette Jara    | Izquierda (PC)               | \"jara\", \"jeannette\", \"jeanette\"    |\n\nEsta selección permite analizar tanto la **competencia intra-derecha** entre tres corrientes (tradicional, republicana, libertaria) como la **convergencia discursiva** frente a un adversario ideológico común en segunda vuelta (el Partido Comunista).\n\n## Consideraciones éticas\n\nLa investigación se rige por principios éticos establecidos para la investigación con datos digitales (Salganik, 2019; Zimmer & Kinder-Kurlanda, 2017):\n\n**Consentimiento y datos públicos**: Los datos recolectados provienen de publicaciones y comentarios realizados en espacios públicos de la plataforma, donde los usuarios tienen expectativas razonables de que su contenido será visible para audiencias amplias. No se accedió a contenido privado, mensajes directos ni información restringida.\n\n**Anonimización**: Aunque los nombres de usuario en Reddit son seudónimos, el análisis no reporta identificadores individuales ni busca vincular cuentas con identidades reales. Los ejemplos citados en el análisis son anonimizados cuando resulta necesario.\n\n**Minimización de daños**: La investigación no interviene en las comunidades estudiadas ni expone a sus miembros a riesgos adicionales. El objetivo es comprender dinámicas colectivas, no escrutinizar comportamientos individuales.\n\n**Reproducibilidad**: Los scripts de recolección y procesamiento se documentan para permitir la replicación del estudio, respetando los términos de uso de la API de Reddit.\n\n## Técnicas de análisis\n\n### Análisis de sentimiento y emociones\n\nPara identificar los patrones emocionales del corpus, se implementó análisis de sentimiento mediante modelos de procesamiento de lenguaje natural entrenados para español. Se empleó una aproximación multidimensional que distingue entre:\n\n-   **Polaridad**: Valencia positiva, negativa o neutra del contenido.\n\n-   **Intensidad**: Grado de activación emocional.\n\n-   **Emociones discretas**: Identificación de emociones específicas (alegría, tristeza, miedo, ira, sorpresa, asco) cuando los modelos lo permiten.\n\n### Modelado de tópicos\n\nPara identificar los marcos interpretativos y temas estructurantes del debate, se implementaron técnicas de **modelado de tópicos** (*topic modeling*). Estas técnicas permiten descubrir patrones temáticos latentes en grandes corpus textuales, identificando agrupaciones de palabras que tienden a co-ocurrir y que pueden interpretarse como \"temas\" o, en el marco teórico de esta investigación, como indicadores de *frames*.\n\n### Análisis de redes de interacción\n\nPara examinar las dinámicas interaccionales, se construyeron **redes de respuesta** donde los nodos representan usuarios y las aristas representan relaciones de respuesta (comentario a comentario). Este análisis permite identificar patrones de interacción entre usuarios de distintas orientaciones ideológicas, la existencia de subcomunidades discursivas y las dinámicas de confrontación o cooperación.\n\n### Análisis temporal\n\nEl diseño longitudinal permite implementar análisis de **series temporales** que examinan cómo varían los indicadores de interés a lo largo del período estudiado. Esto incluye la identificación de tendencias, ciclos, puntos de quiebre y la correlación entre eventos externos (debates, declaraciones, escándalos) y cambios en los patrones discursivos.\n\n## Volumen y estructura del corpus final\n\nAl cierre de la recolección (31 de diciembre de 2024), el corpus construido contiene:\n\n-   Todos los posts publicados en r/chile y r/RepublicadeChile durante el período que mencionan al menos una figura política de interés.\n\n-   Todos los comentarios dentro de esos posts que mencionan a dichas figuras.\n\n-   Estructura temporal completa desde el 1 de agosto al 31 de diciembre de 2024.\n\n-   Metadatos asociados que permiten análisis longitudinal, de red y de interacción.\n\nEste diseño metodológico permite observar la configuración de la conversación política en Reddit y su evolución durante la campaña presidencial chilena de 2025, con foco específico en patrones de enmarcamiento (*framing*), movilización emocional y construcción de adversarios a lo largo del ciclo electoral.\n",
    "supporting": [
      "03-obtencion-datos_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}